# Wasserstein-Cycle-GAN-for-Surface-Wave-Tomography
Code and Benchmark Examples for a paper in JGR: Solid Earth

**Cai, A., Qiu, H., & Niu, F. (2022). Semi-supervised surface wave tomography with Wasserstein cycle-consistent GAN: Method and application to Southern California plate boundary region** <br />
Journal of Geophysical Research: Solid Earth, 127, e2021JB023598. <br />
https://doi.org/10.1029/2021JB023598

## Basic Notations <br />
The name of the deep learning method is **Wasserstein Cycle-GAN-GP**, a hybrid method of **Wasserstein GAN-GP** (*Arjovsky and Bottou, 2017; Arjovsky et al., 2017*) and **Cycle-GAN** (*Yi et al., 2017; Zhu et al., 2017*). **GP** stands for gradient penalty.

You can redistribute it and/or modify it under the terms of the GNU General Public License version 3.0. <br />
If you show inversion results in a paper or presentation please give a reference to the JGR paper

If you have questions when using the package, you can contact me at aocai166@gmail.com <br />

The code is writing in Python using the **TensorFlow** framework. Benchmark examples are given below. <br />

## Benckmark Examples
### (1) Setup your environment <br />
The Anaconda enviroment file (*environment.yml*) used in Cai et al. (2022) is provided. <br />
You can copy my environment using the yml file. <br />

An **tutorial** can be found here: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html

**Note**: due to the time of development of this code (2020), I used **TensorFlow 1.14**. It might not be compatable with the recent TensorFlow 2 and above versions.

### (2) Download the data **Data/** <br />
#### Labeled data <br />
Generated by first extracting 1-D *Vs* profiles from the Southern California Earthquake Center (SCEC) Community Velocity Model of *Shaw et al. (2015; CVMH)*. <br />
Then the theoretical Rayleigh wave dispersion curves are calculated using the *Herrmann (2013)* package.

There are three set of labeled data. <br />
-The **16480** labeled dispersion data (**Vs_region** & **disp_region**) <br />
-The **16480** labeled dispersion data + Position information (**Vs_region** & **disp_pos_region**) <br />
-The downsampled **1890** labeled dispersion data (**Vs_grid01** & **disp_gird01**) <br />

The dataset consists of text file for every grid cell. The name of the file contains the information of its latitude and longitude. For instance:

<pre> 1_32.600_239.800.txt  --> Latitude 32.6N; Longitude 120.2W. </pre>

For the data files, they include: <br />
<pre> Periods (3s-16s)    Phase Velocity (km/s)    Group Velocity (km/s)    Latitude    Longtitude </pre>
For the Vs profiles, they include: <br />
<pre> Depth (0km-49.0km)    Shear Wave Velocity (Vs; km/s) </pre>

#### Unlabeled data <br />
The unlabeled dispersion curves are 4076 observed Rayleigh wave dispersion curves extracted from *Qiu et al. (2019)*. They are stored as a 3-D matrix in *.npy* format for simplicity <br />

**Test_data_Qiu.npy** <br />
A (4076, 17, 5) matrix, containing the information of <br />
<pre> Longtitude    Latitude    Periods (3s-16s)    Phase Velocity (km/s)    Group Velocity (km/s) </pre>

**Test_data_Qiu_sigma.npy** <br />
A (4076, 17, 7) matrix, containing the information of <br />
<pre> Longtitude    Latitude    Periods (3s-16s)    Phase Velocity (km/s)    Group Velocity (km/s)    Uncertainty of Phase Velocity (km/s)    Uncertainty of Group Velocity (km/s)</pre>


To play around with this, please put the code and data to whatever folder you would like to in you computer/server. Look at "Wcyclegan-gp-tf_Vs_inv_1D.py", all the parameters are settled down. What you need to change is the "self.file_train_path" to the path of where you have put the data folder, change "self.out_path" to where you want to have figure outputs and final models. You don't necessarily need to change "self.test_disp_path", but just in case, make it the same as the file_train_path.

Then you can run this file and the training will start, you need to build up the environment to run this code, an easy way to know what to install is looking at all the "import ...", then you know what packages are needed, they can be easily installed in the anaconda environment. What's important is that please use the tensorflow version 1.14.0. The current code is not compatible with tensorflow version higher than 2.0.

To control trian/test/apply on unlabeled data, look at the bottom of "Wcyclegan-gp-tf_Qiu_1D.py", you will see "Train", "Test" and "Predict" modes are available. Simply change the mode value will work. But when you want to use "Test" and "Predict" module, please first generate a folder named "predict" in your output directory.

![Figure7](https://user-images.githubusercontent.com/35436104/154765285-227c78f2-667c-4b53-a232-7c6fb84e2e75.JPG)

## References
*Arjovsky, M., & Bottou, L. (2017). Towards Principled Methods for Training Generative Adversarial Networks. 5th International Conference on Learning Representations. Retrieved from https://arxiv.org/abs/1701.04862v1*

*Arjovsky, M., Chintala, S., & Bottou, L. (2017). Wasserstein GAN. Retrieved from http://arxiv.org/abs/1701.07875*

*Herrmann, R. B. (2013). Computer programs in seismology: An evolving tool for instruction and research. Seismological Research Letters, 84(6), 1081–1088. https://doi.org/10.1785/0220110096*

*Qiu, H., Lin, F. C., & Ben-Zion, Y. (2019). Eikonal Tomography of the Southern California Plate Boundary Region. Journal of Geophysical Research: Solid Earth, 124(9), 9755–9779. https://doi.org/10.1029/2019JB017806*

*Shaw, J. H., Plesch, A., Tape, C., Suess, M. P., Jordan, T. H., Ely, G., et al. (2015). Unified Structural Representation of the southern California crust and upper mantle. Earth and Planetary Science Letters, 415, 1–15. https://doi.org/10.1016/j.epsl.2015.01.016*

*Yi, Z., Zhang, H., Tan, P., & Gong, M. (2017). DualGAN: Unsupervised Dual Learning for Image-to-Image Translation. Proceedings of the IEEE International Conference on Computer Vision, 2017-October, 2868–2876. https://doi.org/10.1109/ICCV.2017.310*

*Zhu, J.-Y., Park, T., Isola, P., Efros, A. A., & Research, B. A. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks Monet Photos. Retrieved from https://github.com/junyanz/CycleGAN.*
